# -*- coding: utf-8 -*-
"""7072CEM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pzlhqgOoTZICdPFzSNwxhvQVVNwnjVEn
"""

import pandas as pd
import numpy as np
import math
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder

dataframe = pd.read_csv("/content/drive/MyDrive/s21.csv", header=None)

dataframe.head()

dataframe.tail()

dataframe.info()

#Data Pre-Processing
print(dataframe)
dataframe.select_dtypes(object)

dataframe.describe()

dataframe.shape

dataframe.isnull().sum()

for col in dataframe.columns:
    print('{} : {}'.format(col,dataframe[col].unique()))

for col in dataframe.columns:
    dataframe[col].replace({'?':np.nan},inplace=True)

dataframe.head()

dataframe.isnull().sum()

sns.heatmap(dataframe.isnull(),cbar=True,cmap='ocean')

# Get correlation matrix values
corr = dataframe.corr()
# Visualizing correlation values using seaborn
sns.heatmap(corr, annot=True)

plt.figure(figsize=(25,10))
sns.heatmap(dataframe.corr(),cbar=True,annot=True,cmap='OrRd')

X2 = dataframe.iloc[:,30:32]
X2 = X2.apply(LabelEncoder().fit_transform)

X = dataframe.iloc[:,0:30]
y = dataframe[31]

len(X)

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn import metrics
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import StackingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.metrics import f1_score

"""###Splitting dataset for training & testing purpose"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = 451)

"""###Naive Bayes Algo"""

from sklearn.naive_bayes import GaussianNB
nb = GaussianNB()
nb.fit(X_train, y_train)
y_pred_nb = nb.predict(X_test)
print (metrics.accuracy_score(y_test, y_pred_nb))
nb_test_accuracy = accuracy_score(y_test, y_pred_nb)

nb.score(X_test, y_test)

y_pred_nb = nb.predict(X_test)
y_pred_nb

accuracy_score(y_pred_nb, y_test)*100

y_pred_nb, y_test

from sklearn.metrics import confusion_matrix
# creating a Confusion matrix
confusion_matrix_nb = confusion_matrix(y_test,y_pred_nb)
confusion_matrix_nb

sns.heatmap(confusion_matrix_nb, annot=True,cmap='Blues',annot_kws={"size": 30})
sns.set(rc={'figure.figsize':(20,10)})
plt.show()

print('True Positive:\t{}'.format(confusion_matrix_nb[0,0]))
print('True Negative:\t{}'.format(confusion_matrix_nb[0,1]))
print('False Positive:\t{}'.format(confusion_matrix_nb[1,0]))
print('False Negative:\t{}'.format(confusion_matrix_nb[1,1]))

# Confusion Matrix Metrics
from sklearn.metrics import classification_report
matrix = classification_report(y_test,y_pred_nb)
print("classification_report: \n", matrix)

nb_test_f1 = f1_score(y_test, y_pred_nb, average='weighted') # Calculate F1-score
print('- F1 score: %s' % nb_test_f1)

sensitivitynb = confusion_matrix_nb[0,0]/(confusion_matrix_nb[0,0]+confusion_matrix_nb[0,1])
print('Sensitivity : ', sensitivitynb )

specificitynb = confusion_matrix_nb[1,1]/(confusion_matrix_nb[1,0]+confusion_matrix_nb[1,1])
print('Specificity : ', specificitynb)

"""###KNN Algo"""

knn = KNeighborsClassifier(n_neighbors = 5)
knn.fit(X_train, y_train)
y_pred_knn = knn.predict(X_test)
print (metrics.accuracy_score(y_test, y_pred_knn))
knn_test_accuracy = accuracy_score(y_test, y_pred_knn)

knn.score(X_test, y_test)*100

y_pred_knn = knn.predict(X_test)
y_pred_knn

accuracy_score(y_pred_knn, y_test)

y_pred_knn, y_test

# creating a Confusion matrix
confusion_matrix_knn = confusion_matrix(y_test,y_pred_knn)

confusion_matrix_knn

sns.heatmap(confusion_matrix_knn, annot=True,cmap='Blues',annot_kws={"size": 30})
sns.set(rc={'figure.figsize':(20,10)})
plt.show()

print('True Positive:\t{}'.format(confusion_matrix_knn[0,0]))
print('True Negative:\t{}'.format(confusion_matrix_knn[0,1]))
print('False Positive:\t{}'.format(confusion_matrix_knn[1,0]))
print('False Negative:\t{}'.format(confusion_matrix_knn[1,1]))

# Confusion Matrix Metrics

matrix = classification_report(y_test,y_pred_knn)
print("classification_report: \n", matrix)

knn_test_f1 = f1_score(y_test, y_pred_knn, average='weighted') # Calculate F1-score
print('- F1 score: %s' % knn_test_f1)

sensitivityknn = confusion_matrix_knn[0,0]/(confusion_matrix_knn[0,0]+confusion_matrix_knn[0,1])
print('Sensitivity : ', sensitivityknn )

specificityknn = confusion_matrix_knn [1,1]/(confusion_matrix_knn [1,0]+confusion_matrix_knn [1,1])
print('Specificity : ', specificityknn)

"""###Decision Tree Algo"""

dt = DecisionTreeClassifier()
dt.fit(X_train, y_train)
y_pred_dt = dt.predict(X_test)
print (metrics.accuracy_score(y_test, y_pred_dt))
dt_test_accuracy = accuracy_score(y_test, y_pred_dt)

dt.score(X_test, y_test)

y_pred_dt = dt.predict(X_test)
y_pred_dt

accuracy_score(y_pred_dt, y_test)*100

y_pred_dt, y_test

# creating a Confusion matrix
confusion_matrix_dt = confusion_matrix(y_test,y_pred_dt)

confusion_matrix_dt

sns.heatmap(confusion_matrix_dt, annot=True,cmap='Blues',annot_kws={"size": 30})
sns.set(rc={'figure.figsize':(20,10)})
plt.show()
print('True Positive:\t{}'.format(confusion_matrix_dt[0,0]))
print('True Negative:\t{}'.format(confusion_matrix_dt[0,1]))
print('False Positive:\t{}'.format(confusion_matrix_dt[1,0]))
print('False Negative:\t{}'.format(confusion_matrix_dt[1,1]))

# Confusion Matrix Metrics

matrix = classification_report(y_test,y_pred_dt)
print("classification_report: \n", matrix)

dt_test_f1 = f1_score(y_test, y_pred_dt, average='weighted') # Calculate F1-score
print('- F1 score: %s' % dt_test_f1)

sensitivitydt = confusion_matrix_dt[0,0]/(confusion_matrix_dt[0,0]+confusion_matrix_dt[0,1])
print('Sensitivity : ', sensitivitydt )

specificitydt = confusion_matrix_dt[1,1]/(confusion_matrix_dt[1,0]+confusion_matrix_dt[1,1])
print('Specificity : ', specificitydt)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 451,stratify = y)

from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from sklearn.ensemble import StackingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.metrics import f1_score

estimator_list = [
    ('knn',knn),
    ('dt',dt),
    ('nb',nb),
     ]

# Build stack model
stack_model = StackingClassifier(
    estimators=estimator_list, final_estimator=LogisticRegression()
)

# Train stacked model
stack_model.fit(X_train, y_train)

# Make predictions
y_train_pred = stack_model.predict(X_train)
y_test_pred = stack_model.predict(X_test)

# Training set model performance
stack_model_train_accuracy = accuracy_score(y_train, y_train_pred) # Calculate Accuracy
stack_model_train_f1 = f1_score(y_train, y_train_pred, average='weighted') # Calculate F1-score

# Test set model performance
stack_model_test_accuracy = accuracy_score(y_test, y_test_pred) # Calculate Accuracy
stack_model_test_f1 = f1_score(y_test, y_test_pred, average='weighted') # Calculate F1-score

print('Model performance for Training set')
print('- Accuracy: %s' % stack_model_train_accuracy)
print('- F1 score: %s' % stack_model_train_f1)
print('----------------------------------')
print('Model performance for Test set')
print('- Accuracy: %s' % stack_model_test_accuracy)
print('- F1 score: %s' % stack_model_test_f1)

stack_model.score(X_test, y_test)

y_pred_stack_model = stack_model.predict(X_test)
y_pred_stack_model

accuracy_score(y_pred_stack_model, y_test)*100

y_pred_stack_model, y_test

"""# ***Confusion matrix***"""

# creating a Confusion matrix
stack_model = confusion_matrix(y_test,y_pred_stack_model)
stack_model

sns.heatmap(stack_model, annot=True,cmap='Blues',annot_kws={"size": 30})
sns.set(rc={'figure.figsize':(20,10)})
plt.show()

print('True Positive:\t{}'.format(stack_model[0,0]))
print('True Negative:\t{}'.format(stack_model[0,1]))
print('False Positive:\t{}'.format(stack_model[1,0]))
print('False Negative:\t{}'.format(stack_model[1,1]))

# Confusion Matrix Metrics

matrix = classification_report(y_test,y_pred_stack_model)
print("classification_report: \n", matrix)

sensitivity_stack_model = stack_model[0,0]/(stack_model[0,0]+stack_model[0,1])
print('SensitivityANN : ', sensitivity_stack_model )

specificity_stack_model = stack_model[1,1]/(stack_model[1,0]+stack_model[1,1])
print('SpecificityANN : ', specificity_stack_model)

acc_test_list = {
'knn':knn_test_accuracy,
'dt': dt_test_accuracy,
'nb': nb_test_accuracy,
'stack': stack_model_test_accuracy}

import pandas as pd

acc_df = pd.DataFrame.from_dict(acc_test_list, orient='index', columns=['Accuracy'])*100

df = pd.concat([acc_df], axis=1)
df

scores = [knn_test_accuracy  ,dt_test_accuracy ,nb_test_accuracy,stack_model_test_accuracy  ]
algorithms = ["K-Nearest Neighbors","Decision Tree","Naive Bayes", "Stack_model"]    

for i in range(len(algorithms)):
    print("The accuracy score achieved using "+algorithms[i]+" is: "+str(100*(scores[i]))+"%")

sns.set(rc={'figure.figsize':(20,10)})
plt.xlabel("Algorithms")
plt.ylabel("Accuracy score")

sns.barplot(algorithms,scores)

!jupyter nbconvert --to html /content/7072CEM.ipynb